{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic vectorization\n",
    "\n",
    "Vectorizing text is a fundamental concept in analyzing documents. Basically, you can think of it as turning the words in a given text document into counts or weights, represented in what's called a term-document matrix.\n",
    "\n",
    "The library [scikit-learn](http://scikit-learn.org/stable/) has some handy tools for this, called vectorizers. Another popular library for this kind of work is called [NLTK](http://www.nltk.org/). \n",
    "\n",
    "Here's an example of how a [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) works, using a simple string representing a piece of legislation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bill_titles = ['An act to amend Section 44277 of the Education Code, relating to teachers.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "term_document_matrix = vectorizer.fit_transform(bill_titles).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 1 1 1 1 1 1 1 2]]\n",
      "[u'44277', u'act', u'amend', u'an', u'code', u'education', u'of', u'relating', u'section', u'teachers', u'the', u'to']\n"
     ]
    }
   ],
   "source": [
    "print term_document_matrix\n",
    "print vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think of this as a spreadsheet with one row and 12 columns. The row corresponds to our document above. The columns each correspond to a word contained in that document (the first is \"44277\", the second is \"act\", etc.) The numbers correspond to the number of times each word appears in that document. You'll see that all words appear once, except the last one, \"to\", which appears twice.\n",
    "\n",
    "Now what happens if we add another bill and run it again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 0 1 0 1 0 1 1 0 1 1 1 2]\n",
      " [0 1 0 1 1 0 1 0 1 0 0 1 0 0 0 1]]\n",
      "[u'44277', u'act', u'amend', u'an', u'care', u'code', u'coverage', u'education', u'health', u'of', u'relating', u'relative', u'section', u'teachers', u'the', u'to']\n"
     ]
    }
   ],
   "source": [
    "bill_titles = ['An act to amend Section 44277 of the Education Code, relating to teachers.',\n",
    "               'An act relative to health care coverage']\n",
    "features = vectorizer.fit_transform(bill_titles).toarray()\n",
    "\n",
    "print features\n",
    "print vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now we've got two rows, each corresponding to a document. The columns correspond to all words contained in BOTH documents, with counts. For example, the first entry from the first column, \"44277', appears once in the first document but zero times in the second. This, basically, is the concept of a term-document matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So what?\n",
    "\n",
    "After you extract text from documents, converting that text into a structured format like this is the first step in doing any kind of sophisticated analysis with it. At the most basic level, a [word cloud](http://www.nytimes.com/interactive/2012/09/04/us/politics/democratic-convention-words.html) is basically just a term-document matrix visualized. But there are other interesting examples as well:\n",
    "\n",
    "For instance, The LA Times' [crime classification analysis]() was [based on](https://github.com/datadesk/lapd-crime-classification-analysis) techniques like this. As did the AP's work on the [Iraq war logs](http://jonathanstray.com/a-full-text-visualization-of-the-iraq-war-logs) (and other things like it).\n",
    "\n",
    "To wrap up, here's how we might take the data from Hillary's e-mail and put it into a format like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = [open('clinton_email.txt').read()] # This has to be presented to the vectorizer as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-53c9bf1734a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "features = vectorizer.fit_transform(text).toarray()\n",
    "\n",
    "print features\n",
    "print vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
